<!--
Copyright (c) 2024 Isao Sonobe
Released under the MIT license
https://opensource.org/license/mit/
-->
<html>
	<head>
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<title>Chat with your PDF</title>
		<meta name="description" content="Chat with your PDF">
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@gradio/lite@4.14.1/dist/lite.css" />
		<style>
			html, body {
				margin: 0;
				padding: 0;
				height: 100%;
				background: var(--body-background-fill);
			}

			footer {
				display: none !important;
			}

			#chatbot {
				height: auto !important;
				min-height: 500px;
			}

			.chatbot {
				white-space: pre-wrap;
			}

			.gallery-item > .gallery {
				max-width: 380px;
			}

			#context > label > textarea {
				scrollbar-width: thin !important;
			}
		</style>
	</head>
	<body>
		<gradio-lite>
			<gradio-requirements>
				pdfminer.six==20231228
				pyodide-http==0.2.1
				janome==0.5.0
				rank_bm25==0.2.2
			</gradio-requirements>

			<gradio-file name="chat_history.json">
[[null, "ようこそ！　PDFのテキストを参照しながら対話できるチャットボットです。\nPDFファイルをアップロードするとテキストが抽出されます。\nメッセージの中に{context}と書くと、抽出されたテキストがその部分に埋め込まれて対話が行われます。他にもPDFのページを検索して参照したり、ページ番号を指定して参照したりすることができます。一番下のExamplesにこれらの例があります。\nメッセージを書くときにShift+Enterを入力すると改行できます。"]]
			</gradio-file>

			<gradio-file name="app.py" entrypoint>
import os

# Gradioによるアナリティクスを無効化
os.putenv("GRADIO_ANALYTICS_ENABLED", "False")
os.environ["GRADIO_ANALYTICS_ENABLED"] = "False"

# openaiライブラリのインストール方法は https://github.com/pyodide/pyodide/issues/4292 を参考にしました。
import micropip
await micropip.install("https://raw.githubusercontent.com/sonoisa/pyodide_wheels/main/multidict/multidict-4.7.6-py3-none-any.whl", keep_going=True)
await micropip.install("https://raw.githubusercontent.com/sonoisa/pyodide_wheels/main/frozenlist/frozenlist-1.4.0-py3-none-any.whl", keep_going=True)
await micropip.install("https://raw.githubusercontent.com/sonoisa/pyodide_wheels/main/aiohttp/aiohttp-4.0.0a2.dev0-py3-none-any.whl", keep_going=True)
await micropip.install("https://raw.githubusercontent.com/sonoisa/pyodide_wheels/main/openai/openai-1.3.7-py3-none-any.whl", keep_going=True)
await micropip.install("https://raw.githubusercontent.com/sonoisa/pyodide_wheels/main/urllib3/urllib3-2.1.0-py3-none-any.whl", keep_going=True)
await micropip.install("ssl")
import ssl
await micropip.install("httpx", keep_going=True)
import httpx
await micropip.install("https://raw.githubusercontent.com/sonoisa/pyodide_wheels/main/urllib3/urllib3-2.1.0-py3-none-any.whl", keep_going=True)
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
await micropip.install("https://raw.githubusercontent.com/sonoisa/pyodide_wheels/main/tiktoken/tiktoken-0.5.1-cp311-cp311-emscripten_3_1_45_wasm32.whl", keep_going=True)


import gradio as gr
import base64
import json
import unicodedata
import re
from pathlib import Path
from dataclasses import dataclass
import asyncio

import pyodide_http
pyodide_http.patch_all()

from pdfminer.pdfinterp import PDFResourceManager
from pdfminer.converter import TextConverter
from pdfminer.pdfinterp import PDFPageInterpreter
from pdfminer.pdfpage import PDFPage
from pdfminer.layout import LAParams
from io import StringIO

from janome.tokenizer import Tokenizer as JanomeTokenizer
from janome.analyzer import Analyzer as JanomeAnalyzer
from janome.tokenfilter import POSStopFilter, LowerCaseFilter
from rank_bm25 import BM25Okapi

from openai import OpenAI, AzureOpenAI
import tiktoken


class URLLib3Transport(httpx.BaseTransport):
	"""
	urllib3を使用してhttpxのリクエストを処理するカスタムトランスポートクラス
	"""
	def __init__(self):
		self.pool = urllib3.PoolManager()

	def handle_request(self, request: httpx.Request):
		payload = json.loads(request.content.decode("utf-8"))
		urllib3_response = self.pool.request(request.method, str(request.url), headers=request.headers, json=payload)
		stream = httpx.ByteStream(urllib3_response.data)
		return httpx.Response(urllib3_response.status, headers=urllib3_response.headers, stream=stream)

http_client = httpx.Client(transport=URLLib3Transport())


@dataclass
class Page:
	"""
	PDFのページ内容
	"""
	number: int
	content: str


OPENAI_TOKENIZER = tiktoken.get_encoding("cl100k_base")
JANOME_TOKENIZER = JanomeTokenizer()
JANOME_ANALYZER = JanomeAnalyzer(tokenizer=JANOME_TOKENIZER, 
	token_filters=[POSStopFilter(["記号,空白"]), LowerCaseFilter()])


def extract_pdf_pages(pdf_filename):
	"""
	PDFファイルからテキストを抽出する。

	Args:
		pdf_filename (str): 抽出するPDFファイルのパス

	Returns:
		list[Page]: PDFの各ページ内容のリスト
	"""

	pages = []
	with open(pdf_filename, "rb") as pdf_file:
		output = StringIO()
		resource_manager = PDFResourceManager()
		laparams = LAParams()
		text_converter = TextConverter(resource_manager, output, laparams=laparams)
		page_interpreter = PDFPageInterpreter(resource_manager, text_converter)

		page_number = 0
		for i_page in PDFPage.get_pages(pdf_file):
			try:
				page_number += 1
				page_interpreter.process_page(i_page)
				page_content = output.getvalue()
				page_content = unicodedata.normalize('NFKC', page_content)
				pages.append(Page(number=page_number, content=page_content))
				output.truncate(0)
				output.seek(0)
			except Exception as e:
				print(e)
				pass

		output.close()
		text_converter.close()

		return pages


def merge_pages_with_page_tag(pages):
	"""
	PDFの各ページ内容を一つの文字列にマージする。
	ただし、chatpdf:pageというタグでページを括る。
	extract_pages_from_page_tag()の逆変換である。

	Args:
		pages (list[Page]): PDFの各ページ内容のリスト

	Returns:
		str: PDFの各ページ内容をマージした文字列
	"""
	document_with_page_tag = ""
	for page in pages:
		document_with_page_tag += f'&lt;chatpdf:page number="{page.number}"&gt;\n{page.content}\n&lt;/chatpdf:page&gt;\n'
	return document_with_page_tag


def extract_pages_from_page_tag(document_with_page_tag):
	"""
	chatpdf:pageというタグで括られた領域をPDFのページ内容と解釈して、Pageオブジェクトのリストに変換する。
	merge_pages_with_page_tag()の逆変換である。

	Args:
		document_with_page_tag (str): chatpdf:pageというタグで各ページが括られた文字列

	Returns:
		list[Page]: Pageオブジェクトのリスト
	"""
	page_tag_pattern = r'&lt;chatpdf:page number="(\d+)"&gt;\n?(.*?)\n?&lt;\/chatpdf:page&gt;\n?'
	matches = re.findall(page_tag_pattern, document_with_page_tag, re.DOTALL)
	pages = [Page(number=int(number), content=content) for number, content in matches]
	return pages


def add_s(values):
	"""
	複数形のsを必要に応じて付けるために用いる関数。
	与えられたリストの要素数が2以上なら"s"を返し、それ以外は""を返す。

	Args:
		values (list[any]): リスト

	Returns:
		str: 要素数が複数なら"s"、それ以外は""
	"""
	return "s" if len(values) > 1 else ""


def get_context_info(characters, tokens):
	"""
	文字数とトークン数の情報を文字列で返す。

	Args:
		characters (str): テキスト
		tokens (list[str]): トークン

	Returns:
		str: 文字数とトークン数の情報を含む文字列
	"""
	char_count = len(characters)
	token_count = len(tokens)
	return f"{char_count:,} character{add_s(characters)}\n{token_count:,} token{add_s(tokens)}"


def update_context_element(pdf_file_obj):
	"""
	PDFファイルからテキストを抽出し、コンテキスト要素を更新する。

	Args:
		pdf_file_obj (File): アップロードされたPDFファイルオブジェクト

	Returns:
		Tuple: コンテキストテキストボックスに格納する抽出されたテキスト情報と、その文字数情報
	"""
	pages = extract_pdf_pages(pdf_file_obj.name)
	document_with_tag = merge_pages_with_page_tag(pages)
	return gr.update(value=document_with_tag, interactive=True), count_characters(document_with_tag)


def count_characters(document_with_tag):
	"""
	テキストの文字数とトークン数を計算する。
	ただし、テキストはchatpdf:pageというタグでページが括られているとする。

	Args:
		document_with_tag (str): 文字数とトークン数を計算するテキスト

	Returns:
		str: 文字数とトークン数の情報を含む文字列
	"""
	text = "".join([page.content for page in extract_pages_from_page_tag(document_with_tag)])

	tokens = OPENAI_TOKENIZER.encode(text)
	return get_context_info(text, tokens)


class SearchEngine:
	"""
	検索エンジン
	"""
	def __init__(self, engine, pages):
		self.engine = engine
		self.pages = pages


SEARCH_ENGINE = None

def create_search_engine(context):
	"""
	検索エンジンを作る。

	Args:
		context (str): 検索対象となるテキスト。ただし、テキストはchatpdf:pageというタグでページが括られているとする。
	"""
	global SEARCH_ENGINE

	pages = extract_pages_from_page_tag(context)
	tokenized_pages = []
	original_pages = []
	for page in pages:
		page_content = page.content.strip()
		if page_content:
			tokenized_page = [token.base_form for token in JANOME_ANALYZER.analyze(page_content)]
			if tokenized_page:
				tokenized_pages.append(tokenized_page)
				original_pages.append(page)

	if tokenized_pages:
		bm25 = BM25Okapi(tokenized_pages)
		SEARCH_ENGINE = SearchEngine(engine=bm25, pages=original_pages)
	else:
		SEARCH_ENGINE = None


def search_pages(keywords, page_limit):
	"""
	与えられたキーワードを含むページを検索する。

	Args:
		keywords (str): 検索キーワード
		page_limit (int): 検索するページ数

	Returns:
		list[Page]: ヒットしたページ
	"""
	global SEARCH_ENGINE
	if SEARCH_ENGINE is None:
		return []

	tokenized_query = [token.base_form for token in JANOME_ANALYZER.analyze(keywords)]
	if not tokenized_query:
		return []

	found_pages = SEARCH_ENGINE.engine.get_top_n(tokenized_query, SEARCH_ENGINE.pages, n=page_limit)
	return found_pages


def load_pages(page_numbers):
	"""
	与えられたページ番号のページを取得する。

	Args:
		page_numbers (list[int]): 取得するページ番号

	Returns:
		list[Page]: 取得したページ
	"""
	global SEARCH_ENGINE
	if SEARCH_ENGINE is None:
		return []

	page_numbers = set(page_numbers)
	found_pages = [page for page in SEARCH_ENGINE.pages if page.number in page_numbers]
	return found_pages


CHAT_TOOLS = [
	# ページ検索
	{
		"type": "function",
		"function": {
			"name": "search_pages",
			"description": "与えられたキーワードを含むページを検索します。",
			"parameters": {
				"type": "object",
				"properties": {
					"keywords": {
						"type": "string",
						"description": "半角空白区切りの複数の検索キーワード, 例: Artificial General Intelligence 自律エージェント"
					},
					"page_limit": {
						"type": "number",
						"description": "検索するページ数, 例: 3",
						"minimum": 1
					}
				}
			},
			"required": ["keywords"]
		}
	}, 
	# ページ取得
	{
		"type": "function",
		"function": {
			"name": "load_pages",
			"description": "与えられたページ番号のページを取得します。",
			"parameters": {
				"type": "object",
				"properties": {
					"page_numbers": {
						"type": "array",
						"items": {
							"type": "number"
						},
						"minItems": 1,
						"description": "取得するページのページ番号のリスト"
					}
				}
			},
			"required": ["page_numbers"]
		}
	}
]


async def process_prompt(prompt, history, context, platform, endpoint, azure_deployment, azure_api_version, api_key, model_name, max_tokens, temperature):
	"""
	ユーザーのプロンプトを処理し、ChatGPTによる生成結果を返す。

	Args:
		prompt (str): ユーザーからの入力プロンプト
		history (list): チャット履歴
		context (str): チャットコンテキスト
		platform (str): 使用するAIプラットフォーム
		endpoint (str): AIサービスのエンドポイント
		azure_deployment (str): Azureのデプロイメント名
		azure_api_version (str): Azure APIのバージョン
		api_key (str): APIキー
		model_name (str): 使用するAIモデルの名前
		max_tokens (int): 生成する最大トークン数
		temperature (float): クリエイティビティの度合いを示す温度パラメータ

	Returns:
		str: ChatGPTによる生成結果
	"""

	pages = extract_pages_from_page_tag(context)
	if pages:
		context = "".join([page.content for page in pages])

	try:
		messages = []
		for user_message, assistant_message in history:
			if user_message is not None and assistant_message is not None:
				user_message = user_message.replace("{context}", context)
				messages.append({ "role": "user", "content": user_message })
				messages.append({ "role": "assistant", "content": assistant_message })

		prompt = prompt.replace("{context}", context)
		messages.append({ "role": "user", "content": prompt })

		if platform == "OpenAI":
			openai_client = OpenAI(
					base_url=endpoint,
					api_key=api_key,
					http_client=http_client
				)
		else: # Azure
			openai_client = AzureOpenAI(
					azure_endpoint=endpoint,
					api_version=azure_api_version,
					azure_deployment=azure_deployment,
					api_key=api_key,
					http_client=http_client
				)

		completion = openai_client.chat.completions.create(
				messages=messages,
				model=model_name,
				max_tokens=max_tokens,
				temperature=temperature,
				tools=CHAT_TOOLS,
				tool_choice="auto",
				stream=False
			)

		bot_response = ""
		if hasattr(completion, "error"):
			raise gr.Error(completion.error["message"])

		response_message = completion.choices[0].message
		tool_calls = response_message.tool_calls
		if tool_calls:
			messages.append(response_message)

			for tool_call in tool_calls:
				function_name = tool_call.function.name
				function_args = json.loads(tool_call.function.arguments)
				if function_name == "search_pages":
					# ページ検索
					keywords = function_args.get("keywords").strip()
					page_limit = function_args.get("page_limit") or 3

					bot_response += f'Searching for pages containing the keyword{add_s(keywords.split(" "))} "{keywords}".\n'

					found_pages = search_pages(keywords, page_limit)
					function_response = json.dumps({
							"status": "found" if found_pages else "not found",
							"found_pages": [{
								"page_number": page.number,
								"page_content": page.content
							} for page in found_pages]
						}, ensure_ascii=False)
					messages.append({
							"tool_call_id": tool_call.id,
							"role": "tool",
							"name": function_name,
							"content": function_response
						})
					if found_pages:
						bot_response += f'Found page{add_s(found_pages)}: {", ".join([str(page.number) for page in found_pages])}.\n\n'
					else:
						bot_response += "Page not found.\n\n"
				elif function_name == "load_pages":
					# ページ取得
					page_numbers = function_args.get("page_numbers")

					bot_response += f'Trying to load page{add_s(page_numbers)} {", ".join(map(str, page_numbers))}.\n'

					found_pages = load_pages(page_numbers)
					function_response = json.dumps({
							"status": "found" if found_pages else "not found",
							"found_pages": [{
								"page_number": page.number,
								"page_content": page.content
							} for page in found_pages]
						}, ensure_ascii=False)
					messages.append({
							"tool_call_id": tool_call.id,
							"role": "tool",
							"name": function_name,
							"content": function_response
						})
					if found_pages:
						bot_response += f'Found page{add_s(found_pages)}: {", ".join([str(page.number) for page in found_pages])}.\n\n'
					else:
						bot_response += "Page not found.\n\n"

			yield bot_response + "Generating response. Please wait a moment...\n"
			await asyncio.sleep(0.1)

			completion = openai_client.chat.completions.create(
					messages=messages,
					model=model_name,
					max_tokens=max_tokens,
					temperature=temperature,
					stream=False
				)

			if hasattr(completion, "error"):
				raise gr.Error(completion.error["message"])

			response_message = completion.choices[0].message
			bot_response += response_message.content
			yield bot_response

		else:
			bot_response += response_message.content
			yield bot_response

	except Exception as e:
		if hasattr(e, "message"):
			raise gr.Error(e.message)
		else:
			raise gr.Error(str(e))


def load_api_key(file_obj):
	"""
	APIキーファイルからAPIキーを読み込む。

	Args:
		file_obj (File): APIキーファイルオブジェクト

	Returns:
		str: 読み込まれたAPIキー文字列
	"""	
	try:
		with open(file_obj.name, "r", encoding="utf-8") as api_key_file:
			return api_key_file.read().strip()
	except Exception as e:
		raise gr.Error(str(e))


def main():
	"""
	アプリケーションのメイン関数。Gradioインターフェースを設定し、アプリケーションを起動する。
	"""
	try:
		# クエリパラメータに保存されていることもあるチャット履歴を読み出す。
		with open("chat_history.json", "r", encoding="utf-8") as f:
			CHAT_HISTORY = json.load(f)
	except Exception as e:
		print(e)
		CHAT_HISTORY = []

	# localStorageから設定情報ををロードする。
	js_define_utilities_and_load_settings = """() =&gt; {
			const KEY_PREFIX = "serverless_chat_with_your_pdf:";

			const loadSettings = () =&gt; {
				const getItem = (key, defaultValue) =&gt; {
					const jsonValue = localStorage.getItem(KEY_PREFIX + key);
					if (jsonValue) {
						return JSON.parse(jsonValue);
					} else {
						return defaultValue;
					}
				};

				const platform = getItem("platform", "OpenAI");
				const endpoint = getItem("endpoint", "https://api.openai.com/v1");
				const azure_deployment = getItem("azure_deployment", "");
				const azure_api_version = getItem("azure_api_version", "");
				const model_name = getItem("model_name", "gpt-4-turbo-preview");
				const max_tokens = getItem("max_tokens", 4096);
				const temperature = getItem("temperature", 0.2);
				const save_chat_history_to_url = getItem("save_chat_history_to_url", false);

				return [platform, endpoint, azure_deployment, azure_api_version, model_name, max_tokens, temperature, save_chat_history_to_url];
			};

			globalThis.resetSettings = () =&gt; {
				for (let key in localStorage) {
					if (key.startsWith(KEY_PREFIX)) {
						localStorage.removeItem(key);
					}
				}

				return loadSettings();
			};

			globalThis.saveItem = (key, value) =&gt; {
				localStorage.setItem(KEY_PREFIX + key, JSON.stringify(value));
			};

			return loadSettings();
		}
		"""

	# should_saveがtrueであればURLにチャット履歴を保存し、falseであればチャット履歴を削除する。
	save_or_delete_chat_history = '''(hist, should_save) =&gt; {
			saveItem("save_chat_history_to_url", should_save);
			if (!should_save) {
				const url = new URL(window.location.href);
				url.searchParams.delete("history");
				window.history.replaceState({path:url.href}, '', url.href);
			} else {
				const compressedHistory = LZString.compressToEncodedURIComponent(JSON.stringify(hist));
				const url = new URL(window.location.href);
				url.searchParams.set("history", compressedHistory);
				window.history.replaceState({path:url.href}, '', url.href);
			}
		}'''

	# メッセージ例
	examples = {
		"要約 (論文)": '''制約条件に従い、以下の研究論文で提案されている技術や手法について要約してください。

# 制約条件
* 要約者: 大学教授
* 想定読者: 大学院生
* 要約結果の言語: 日本語
* 要約結果の構成（以下の各項目について500文字）:
  1. どんな研究であるか
  2. 先行研究に比べて優れている点は何か
  3. 提案されている技術や手法の重要な点は何か
  4. どのような方法で有効であると評価したか
  5. 何か議論はあるか
  6. 次に読むべき論文は何か

# 研究論文
"""
{context}
"""

# 要約結果''', 
		"要約 (一般)": '''制約条件に従い、以下の文書の内容を要約してください。

# 制約条件
* 要約者: 技術コンサルタント
* 想定読者: 経営層、CTO、CIO
* 形式: 箇条書き
* 分量: 20項目
* 要約結果の言語: 日本語

# 文書
"""
{context}
"""

# 要約''', 
		"情報抽出": '''制約条件に従い、以下の文書から情報を抽出してください。

# 制約条件
* 抽出する情報: 課題や問題点について言及している全ての文。一つも見落とさないでください。
* 出力形式: 箇条書き
* 出力言語: 元の言語の文章と、その日本語訳

# 文書
"""
{context}
"""

# 抽出結果''', 
		"QA (RAG)": '''次の質問に回答するために役立つページを検索して、その検索結果を使って回答して下さい。

# 制約条件
* 検索クエリの生成方法: 質問文の3つの言い換え（paraphrase）をカンマ区切りで連結した文字列
* 検索クエリの言語: 英語
* 検索するページ数: 3
* 回答方法: 
  - 検索結果の情報のみを用いて回答すること。
  - 回答に利用した文章のあるページ番号を最後に出力すること。形式: "参考ページ番号: 71, 59, 47"
  - 回答に役立つ情報が検索結果内にない場合は「検索結果には回答に役立つ情報がありませんでした。」と回答すること。
* 回答の言語: 日本語

# 質問
どのような方法で、提案された手法が有効であると評価しましたか？

# 回答''', 
		"要約 (RAG)": '''次のキーワードを含むページを検索して、その検索結果をページごとに要約して下さい。

# 制約条件
* キーワード: dataset datasets
* 検索するページ数: 3
* 要約結果の言語: 日本語
* 要約の形式:
  ## ページ番号（例: 12ページ）
  - 要約文1
  - 要約文2
  ...
* 要約の分量: 各ページ3項目

# 要約''', 
		"翻訳 (RAG)": '''次のキーワードを含むページを検索して、その検索結果を日本語に翻訳して下さい。

# 制約条件
* キーワード: dataset datasets
* 検索するページ数: 1

# 翻訳結果''', 
		"要約 (ページ指定)": '''16〜17ページをページごとに箇条書きで要約して下さい。

# 制約条件
* 要約結果の言語: 日本語
* 要約の形式:
  ## ページ番号（例: 12ページ）
  - 要約文1
  - 要約文2
  ...
* 要約の分量: 各ページ5項目

# 要約''', 
		"続きを生成": "続きを生成してください。"
	}

	with gr.Blocks(theme=gr.themes.Default(), analytics_enabled=False) as app:
		with gr.Tabs():
			with gr.TabItem("Settings"):
				with gr.Row():
					with gr.Column():
						platform = gr.Radio(label="Platform", interactive=True, 
							choices=["OpenAI", "Azure"], value="OpenAI")
						platform.change(None, inputs=platform, outputs=None, 
							js='(x) =&gt; saveItem("platform", x)', show_progress="hidden")

						with gr.Row():
							endpoint = gr.Textbox(label="Endpoint", interactive=True)
							endpoint.change(None, inputs=endpoint, outputs=None, 
								js='(x) =&gt; saveItem("endpoint", x)', show_progress="hidden")

							azure_deployment = gr.Textbox(label="Azure Deployment", interactive=True)
							azure_deployment.change(None, inputs=azure_deployment, outputs=None, 
								js='(x) =&gt; saveItem("azure_deployment", x)', show_progress="hidden")

							azure_api_version = gr.Textbox(label="Azure API Version", interactive=True)
							azure_api_version.change(None, inputs=azure_api_version, outputs=None, 
								js='(x) =&gt; saveItem("azure_api_version", x)', show_progress="hidden")

						with gr.Row():
							api_key_file = gr.File(file_count="single", file_types=["text"], 
								height=80, label="API Key File")
							api_key = gr.Textbox(label="API Key", type="password", interactive=True)
							# 注意: 秘密情報をlocalStorageに保存してはならない。他者に秘密情報が盗まれる危険性があるからである。

							api_key_file.upload(load_api_key, inputs=api_key_file, outputs=api_key, 
								show_progress="hidden")
							api_key_file.clear(lambda: None, inputs=None, outputs=api_key, show_progress="hidden")

						model_name = gr.Textbox(label="model", interactive=True)
						model_name.change(None, inputs=model_name, outputs=None, 
							js='(x) =&gt; saveItem("model_name", x)', show_progress="hidden")

						max_tokens = gr.Number(label="Max Tokens", interactive=True,
							minimum=0, precision=0, step=1)
						max_tokens.change(None, inputs=max_tokens, outputs=None, 
							js='(x) =&gt; saveItem("max_tokens", x)', show_progress="hidden")

						temperature = gr.Slider(label="Temperature", interactive=True,
							minimum=0.0, maximum=1.0, step=0.1)
						temperature.change(None, inputs=temperature, outputs=None, 
							js='(x) =&gt; saveItem("temperature", x)', show_progress="hidden")

						save_chat_history_to_url = gr.Checkbox(label="Save Chat History to URL", interactive=True)

						setting_items = [platform, endpoint, azure_deployment, azure_api_version, model_name, max_tokens, 
							temperature, save_chat_history_to_url]
						reset_button = gr.Button("Reset Settings")
						reset_button.click(None, inputs=None, outputs=setting_items, 
							js="() =&gt; resetSettings()", show_progress="hidden")

			with gr.TabItem("Chat"):
				with gr.Row():
					with gr.Column(scale=1):
						pdf_file = gr.File(file_count="single", file_types=[".pdf"], 
							height=80, label="PDF")
						context = gr.Textbox(elem_id="context", label="Context", lines=20, 
							interactive=True, autoscroll=False, show_copy_button=True)
						char_counter = gr.Textbox(label="Statistics", value=get_context_info("", []), 
							lines=2, max_lines=2, interactive=False, container=True)

						pdf_file.upload(update_context_element, inputs=pdf_file, outputs=[context, char_counter])
						pdf_file.clear(lambda: None, inputs=None, outputs=context, show_progress="hidden")

						(context.change(count_characters, inputs=context, outputs=char_counter, show_progress="hidden")
							.then(create_search_engine, inputs=context, outputs=None))

					with gr.Column(scale=2):
						chatbot = gr.Chatbot(
							CHAT_HISTORY,
							elem_id="chatbot", render=False, height=500, show_copy_button=True,
							sanitize_html=False, render_markdown=False, likeable=False, layout="bubble",
							avatar_images=[None, Path("robot.png")])

						chat_message_textbox = gr.Textbox(placeholder="Type a message...", 
							render=False, container=False, interactive=True, scale=7)

						chatbot.change(None, inputs=[chatbot, save_chat_history_to_url], outputs=None, 
							# チャット履歴をクエリパラメータに保存する。
							js=save_or_delete_chat_history, show_progress="hidden")

						save_chat_history_to_url.change(None, inputs=[chatbot, save_chat_history_to_url], outputs=None, 
							js=save_or_delete_chat_history, show_progress="hidden")

						chat = gr.ChatInterface(process_prompt, 
							title="Chat with your PDF", 
							chatbot=chatbot, 
							textbox=chat_message_textbox, 
							additional_inputs=[context, platform, endpoint, azure_deployment, azure_api_version, api_key, 
								model_name, max_tokens, temperature], 
							examples=None)

						example_title_textbox = gr.Textbox(visible=False, interactive=True)
						gr.Examples([[k] for k, v in examples.items()], 
							inputs=example_title_textbox, outputs=chat_message_textbox, 
							fn=lambda title: examples[title], run_on_click=True)

		app.load(None, inputs=None, outputs=setting_items, 
			js=js_define_utilities_and_load_settings, show_progress="hidden")

	app.queue().launch()

main()
			</gradio-file>

			<!-- DALL-Eを用いて作ったボットアイコン -->
			<gradio-file name="robot.png" url="https://raw.githubusercontent.com/sonoisa/misc/main/resources/icons/chatbot_icon.png" />
		</gradio-lite>

		<script language="javascript" src="https://cdn.jsdelivr.net/npm/lz-string@1.5.0/libs/lz-string.min.js"></script>
		<script language="javascript">
			(function () {
				// クエリパラメータにチャット履歴が記録されていたらそれをロードし、chat_history.jsonファイルに書き出す。
				const url = new URL(window.location.href);

				if (url.searchParams.has("history")) {
					const compressedHistory = url.searchParams.get("history");
					hist = LZString.decompressFromEncodedURIComponent(compressedHistory);

					const chat_history_element = document.querySelector('gradio-file[name="chat_history.json"]');
					chat_history_element.textContent = hist;
				}
			})();
		</script>
		<script type="module" crossorigin src="https://cdn.jsdelivr.net/npm/@gradio/lite@4.14.1/dist/lite.js"></script>
	</body>
</html>